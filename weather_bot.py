import asyncio
import logging
import re
import csv
import os
import requests
from datetime import datetime
from dotenv import load_dotenv
from weather_price_monitor import WeatherPriceMonitor
from engine.config import QuantConfig
from engine.data_feed import WeatherState
from engine.strategy import StrategyKernel
from executor.poly_trader import PolyExecutor
from src.monitor.position_manager import PositionManager
from decimal import Decimal, ROUND_HALF_UP

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

import time

# å…¨å±€å¯åŠ¨æ—¶é—´ï¼Œç”¨äºé™é»˜æœŸåˆ¤æ–­
_STARTUP_TIME = time.time()

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("WeatherBot")

def send_dingtalk_notification(market, contract, price, shares, reason):
    """å‘é€é’‰é’‰äº¤æ˜“æœºä¼šé€šçŸ¥ (å¢åŠ å¯åŠ¨é™é»˜æœŸ)"""
    if time.time() - _STARTUP_TIME < 60:
        logger.info(f"[é’‰é’‰] å¯åŠ¨é™é»˜æœŸï¼Œå¿½ç•¥é€šçŸ¥: {market} {reason}")
        return
        
    webhook = os.getenv("DINGTALK_WEBHOOK")
    if not webhook:
        logger.warning("é’‰é’‰ Webhook æœªé…ç½®ï¼Œè·³è¿‡é€šçŸ¥")
        return
    
    total_cost = price * shares
    
    # æ¶ˆæ¯éœ€è¦åŒ…å«å…³é”®è¯ "Polymarket"
    message = f"""ğŸš¨ Polymarket äº¤æ˜“è§¦å‘æé†’

ğŸ“ å¸‚åœº: {market}
ğŸ¯ ç›®æ ‡åˆçº¦: {contract}
ğŸ’° ä¹°å…¥å•ä»·: {price:.3f} USDC
æŒæœ‰ä»½é¢: {shares:.1f}
æ€»è®¡æˆæœ¬: {total_cost:.2f} USDC
ğŸ“ è§¦å‘ç†ç”±: {reason}
â° æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

è¯·åŠæ—¶å…³æ³¨å®ç›˜åŠ¨æ€ï¼"""
    
    payload = {
        "msgtype": "text",
        "text": {"content": message}
    }
    
    try:
        resp = requests.post(webhook, json=payload, timeout=5)
        if resp.status_code == 200:
            logger.info(f"[é’‰é’‰] é€šçŸ¥å‘é€æˆåŠŸ")
        else:
            logger.warning(f"[é’‰é’‰] é€šçŸ¥å‘é€å¤±è´¥: {resp.text}")
    except Exception as e:
        logger.error(f"[é’‰é’‰] é€šçŸ¥å‘é€å¼‚å¸¸: {e}")


class WeatherBot:
    """å¹¶è¡Œå¤šåŒºåŸŸäº¤æ˜“æœºå™¨äºº"""
    
    def __init__(self):
        self.config = QuantConfig
        self.executor = PolyExecutor(self.config)
        self.pos_manager = PositionManager()
        
    def _get_local_time_info(self, offset):
        """è·å–ç«™ç‚¹æœ¬åœ°æ—¶é—´ä¿¡æ¯: (å°æ—¶æµ®ç‚¹æ•°, HH:MM å­—ç¬¦ä¸²)"""
        import datetime as dt
        from datetime import timezone, timedelta
        utc_now = dt.datetime.now(timezone.utc)
        local_time = utc_now + timedelta(hours=offset)
        hour_float = local_time.hour + local_time.minute / 60.0
        time_str = local_time.strftime("%H:%M")
        return hour_float, time_str

    async def run_location_loop(self, preset_name, interval=60):
        """å•ä¸ªåœ°ç‚¹çš„ç›‘å¬ä¸å†³ç­–é—­ç¯ (æ”¯æŒè·¨å¤©è‡ªåŠ¨åˆ‡æ¢)"""
        from weather_price_monitor import PRESETS
        
        if preset_name not in PRESETS:
            logger.error(f"Preset '{preset_name}' not found!")
            return
            
        conf = PRESETS[preset_name]
        tz_offset = conf.get("tz_offset", 0)
        
        # åˆå§‹æ—¥æœŸä¸å½•åˆ¶æ–‡ä»¶å
        current_date_str = self._get_local_date(tz_offset)
        slug = self._get_dynamic_slug(conf['slug_template'], tz_offset)
        
        # å½•åˆ¶æ–‡ä»¶åæ ¼å¼: weather_recording_{city}_{YYYYMMDD}_{HHMM}.csv
        session_start = datetime.now().strftime('%Y%m%d_%H%M')
        current_recording_file = f"data/recordings/weather_recording_{preset_name}_{session_start}.csv"
        
        monitor = WeatherPriceMonitor(
            conf["icao"], slug, conf["lat"], conf["lon"]
        )
        # ä¸º monitor æŒ‡å®š CSV æ–‡ä»¶ï¼ˆè™½ç„¶ hub ä¹Ÿä¼šè®°å½•ï¼Œä½†ä¿æŒä¸€è‡´æ€§ï¼‰
        monitor.csv_file = current_recording_file
        
        # æ¯ä¸ªåœ°ç‚¹ç»´æŠ¤ç‹¬ç«‹çš„ç‰©ç†çŠ¶æ€
        local_hour, local_time_str = self._get_local_time_info(tz_offset)
        state = WeatherState(
            timestamp=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            local_time=local_time_str,
            local_hour=local_hour
        )
        
        logger.info(f"[+] Loop Started: {preset_name} | Slug: {slug} | TZ: {tz_offset}")

        unit = conf.get("unit", "C")
        
        while True:
            try:
                # æ£€æŸ¥æ—¥æœŸï¼Œå¦‚æœè·¨å¤©åˆ™åˆ·æ–° slug
                now_date_str = self._get_local_date(tz_offset)
                if now_date_str != current_date_str:
                    logger.info(f"[{preset_name:8}] Date changed ({current_date_str} -> {now_date_str}), refreshing slug...")
                    current_date_str = now_date_str
                    slug = self._get_dynamic_slug(conf['slug_template'], tz_offset)
                    monitor.poly_url = f"https://gamma-api.polymarket.com/events?slug={slug}"
                    monitor.event_slug = slug
                    # [å…³é”®] å¼ºåˆ¶åˆ·æ–° CSV æ–‡ä»¶ä»¥å¯¹åº”æ–°äº¤æ˜“æ—¥
                    session_start = datetime.now().strftime('%Y%m%d_%H%M')
                    current_recording_file = f"data/recordings/weather_recording_{preset_name}_{session_start}.csv"
                    monitor.csv_file = current_recording_file
                    # é‡ç½®çŠ¶æ€
                    state.has_traded_today = False
                    state.max_temp_overall = -999.0
                    state.v_fit_history = []
                    logger.info(f"[{preset_name:8}] New Session: {slug} | File: {current_recording_file}")

                # 1. è·å–æœ¬åœ°æ—¶é—´ä¸æ•°æ® (æ³¨å…¥å·®å¼‚åŒ–é‡‡æ ·é—´éš”)
                state.local_hour, state.local_time = self._get_local_time_info(tz_offset)
                loop = asyncio.get_event_loop()
                wd = await loop.run_in_executor(
                    None, 
                    lambda: monitor.fetch_all_sources(
                        om_interval=self.config.INTERVAL_OM, 
                        mn_interval=self.config.INTERVAL_MN
                    )
                )
                prices = await loop.run_in_executor(None, monitor.fetch_polymarket_asks)
                
                # 2. çŠ¶æ€å½•åƒ
                state.timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                state.noaa_curr = wd['sources']['NOAA (METAR)']['curr']
                state.om_curr = wd['sources']['Open-Meteo']['curr']
                state.om_fore = wd['sources']['Open-Meteo']['fore']
                state.mn_curr = wd['sources']['Met.no']['curr']
                state.mn_fore = wd['sources']['Met.no']['fore']
                state.consensus_curr = wd['avg_curr']
                state.consensus_fore = wd['avg_fore']
                
                if state.noaa_curr is not None:
                    state.max_temp_overall = max(state.max_temp_overall, state.noaa_curr)
                if state.om_curr is not None:
                    state.max_temp_om = max(state.max_temp_om, state.om_curr)
                if state.mn_curr is not None:
                    state.max_temp_mn = max(state.max_temp_mn, state.mn_curr)
                
                # ç»´æŠ¤è¿ç»­ä¸‹è·Œè®¡æ•° (NOAA æ ¸å¿ƒåŸºå‡†)
                if state.noaa_curr is not None and state.max_temp_overall > -900:
                    if state.noaa_curr < state.max_temp_overall:
                        state.drop_count += 1
                    else:
                        state.drop_count = 0
                
                if state.om_curr is not None: state.om_history.append(state.om_curr)
                if state.mn_curr is not None: state.mn_history.append(state.mn_curr)
                
                v_fit = (state.om_curr * self.config.W1_OM + state.mn_curr * self.config.W2_MN) if (state.om_curr and state.mn_curr) else None
                if v_fit:
                    state.update_v_fit(v_fit)
                
                for hist in [state.om_history, state.mn_history, state.v_fit_history]:
                    if len(hist) > 10: hist.pop(0)

                # 3. ç­–ç•¥å†³ç­–
                state.market_prices = prices # å­˜å…¥å…¨é‡æŠ¥ä»·
                
                # --- æ–°é€»è¾‘ï¼šNOAA ä¸‹è·Œè§¦å‘ / 17ç‚¹å¼ºä¹° ---
                signal, reason, target_temp = StrategyKernel.calculate_noaa_drop_signal(
                    state, self.config, state.max_temp_overall if state.max_temp_overall > -900 else None, state.has_traded_today
                )
                
                # å…¼å®¹åŸæœ‰ v_fit æ˜¾ç¤º
                logger.info(f"[{preset_name:8}] NOAA: {state.noaa_curr if state.noaa_curr else 0.0:.1f} | Max: {state.max_temp_overall if state.max_temp_overall > -900 else 0.0:.1f} | Status: {signal:5} | Reason: {reason}")

                # 4. æ‰§è¡Œå†³ç­– (Dry Run æˆ– Real)
                if signal in ['BUY_DROP', 'BUY_FORCE']:
                    # ç¡®å®šåˆçº¦ï¼šä½¿ç”¨è§¦å‘æ—¶çš„æ¸©åº¦ (target_temp)
                    # [Unit Conversion] å¦‚æœå•ä½æ˜¯åæ°åº¦ï¼Œè¿›è¡Œè½¬æ¢
                    display_temp = target_temp
                    symbol = "Â°C"
                    if unit == "F" and target_temp is not None:
                        # NWS standard: Round Half Up (Asymmetric)
                        f_temp = target_temp * 1.8 + 32
                        display_temp = int(Decimal(str(f_temp)).quantize(Decimal("1"), rounding=ROUND_HALF_UP))
                        symbol = "Â°F"
                    
                    target_contract_prefix = f"{int(display_temp)}{symbol}"
                    
                    # æ™ºèƒ½æœç´¢åˆçº¦ (å¤„ç† NYC çš„èŒƒå›´åˆçº¦ï¼Œå¦‚ "24-25Â°F")
                    target_contract = target_contract_prefix # é»˜è®¤
                    contract_price = None
                    
                    if prices:
                        found = False
                        for title in prices.keys():
                            # 1. å‰ç¼€/åŒ…å«åŒ¹é…
                            if target_contract_prefix in title:
                                target_contract = title
                                found = True
                                break
                            
                            # 2. åæ°åº¦èŒƒå›´åŒ¹é… (NYC ä¸“ç”¨)
                            if unit == 'F':
                                # åŒ¹é… "X-YÂ°F"
                                range_match = re.search(r'(\d+)-(\d+)Â°F', title)
                                if range_match:
                                    low, high = int(range_match.group(1)), int(range_match.group(2))
                                    if low <= display_temp <= high:
                                        target_contract = title
                                        found = True
                                        break
                                # åŒ¹é… "XÂ°F or below"
                                below_match = re.search(r'(\d+)Â°F or below', title)
                                if below_match and display_temp <= int(below_match.group(1)):
                                    target_contract = title
                                    found = True
                                    break
                                # åŒ¹é… "XÂ°F or higher"
                                higher_match = re.search(r'(\d+)Â°F or higher', title)
                                if higher_match and display_temp >= int(higher_match.group(1)):
                                    target_contract = title
                                    found = True
                                    break
                        
                        p_data = prices.get(target_contract)
                        if p_data:
                            contract_price = p_data.get('yes_ask') if isinstance(p_data, dict) else p_data
                    
                    # [Rule] é€šç”¨ä»·æ ¼æ»¤ç½‘ï¼šæ— è®ºä½•ç§è§¦å‘æ¨¡å¼ï¼Œä»·æ ¼å¿…é¡» > 0.5
                    # è¿™æ˜¯ä¸ºäº†é˜²æ­¢åœ¨æç«¯æ¦‚ç‡ä¸‹ï¼ˆå¦‚æ°”æ¸©è™½ç„¶è·Œäº†ä½†ä»æœ‰å˜æ•°ï¼‰ä¹°å…¥åƒåœ¾åˆçº¦
                    should_execute = True
                    price_val = float(contract_price) if contract_price else 0.0
                    
                    if price_val <= 0.5:
                        should_execute = False
                        reason_prefix = "Force buy" if signal == 'BUY_FORCE' else "Drop buy"
                        reason = f"{reason_prefix} skipped: Price {price_val} <= 0.5"
                        logger.info(f"[{preset_name:8}] {reason} (Contract: {target_contract})")
                        
                        # å‘é€è·³è¿‡é€šçŸ¥
                        send_dingtalk_notification(
                            market=preset_name.upper(),
                            contract=target_contract,
                            price=price_val,
                            shares=0, # No shares bought
                            reason=reason
                        )
                        # æ ‡è®°ä¸ºå·²å®Œæˆï¼ˆé¿å…é‡å¤å°è¯•ï¼‰
                        state.has_traded_today = True

                        # 5. ç‹¬ç«‹äº¤æ˜“å­˜è¯ (New Feature)
                        self._record_trade_event(
                            preset_name=preset_name,
                            city_name=conf.get("city_name", preset_name),
                            local_time=state.local_time,
                            signal=f"SKIP_{signal.split('_')[1]}",
                            slug=slug,
                            contract=target_contract,
                            price=price_val,
                            shares=0,
                            reason=reason
                        )
                            
                    if should_execute:
                        # å‘é€äº¤æ˜“é€šçŸ¥
                        send_dingtalk_notification(
                            market=preset_name.upper(),
                            contract=target_contract,
                            price=price_val,
                            shares=self.config.TRADE_SHARES,
                            reason=reason
                        )
                        
                        # åªæœ‰åœ¨é Dry Run ä¸”æ‹¿åˆ°ä»·æ ¼æ—¶æ‰ä¸‹å•
                        if not self.config.DRY_RUN and contract_price:
                            # è½¬æ¢ä¿¡å·ä¸ºæ ‡å‡† BUY è¿›è¡Œæ‰§è¡Œ
                            await self.executor.execute_trade('BUY', monitor.event_slug, contract_price, self.config.TRADE_SHARES)
                        
                        # æ ‡è®°ä»Šæ—¥å·²äº¤æ˜“
                        state.has_traded_today = True
                        logger.info(f"[{preset_name:8}] âš¡ Trade Triggered ({signal}). Daily trade locked.")

                        # è®°å½•äº¤æ˜“äº‹ä»¶å¹¶å¼€å§‹è¿½è¸ªç”Ÿå‘½å‘¨æœŸ
                        order_id = f"dry_{int(datetime.now().timestamp())}"
                        if not self.config.DRY_RUN:
                            # å®é™…ä¸‹å•æ—¶åº”ä»æ‰§è¡Œå™¨è·å–çœŸå® OrderID
                            # è¿™é‡Œå‡è®¾æ‰§è¡Œå™¨è¿”å›ç»“æœä¸­åŒ…å« order_id
                            pass 

                        self.pos_manager.record_pending_order(
                            city_name=conf.get("city_name", preset_name),
                            local_time=state.local_time,
                            signal=signal,
                            slug=slug,
                            contract=target_contract,
                            price=price_val,
                            shares=self.config.TRADE_SHARES,
                            reason=reason,
                            order_id=order_id,
                            is_dry_run=self.config.DRY_RUN
                        )
                
                self._record_data(current_recording_file, state, prices, signal, reason)

            except Exception as e:
                logger.error(f"[{preset_name}] Loop error: {e}")
                
            await asyncio.sleep(interval)

    def _get_local_date(self, offset):
        """è·å–ç«™ç‚¹æœ¬åœ°æ—¥æœŸå­—ç¬¦ä¸² (YYYY-MM-DD)"""
        import datetime as dt
        from datetime import timezone, timedelta
        utc_now = dt.datetime.now(timezone.utc)
        return (utc_now + timedelta(hours=offset)).strftime("%Y-%m-%d")

    def _record_outcome(self, preset_name, date_str, slug_id, state):
        """ç»“ç®—å¹¶è®°å½•æ¯æ—¥æœ€ç»ˆç»“æœ (Outcome)"""
        data_dir = "data/outcomes"
        os.makedirs(data_dir, exist_ok=True)
        filename = f"{data_dir}/outcome_{preset_name}.csv"
        
        file_exists = os.path.isfile(filename)
        with open(filename, 'a', newline='') as f:
            fieldnames = ['date', 'slug_id', 'noaa_max']
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            if not file_exists:
                writer.writeheader()
            
            # è®°å½•æœ€é«˜æ¸©
            actual_max = f"{state.max_temp_overall:.2f}" if state.max_temp_overall > -900 else "N/A"
            
            writer.writerow({
                'date': date_str,
                'slug_id': slug_id,
                'noaa_max': actual_max
            })
            logger.info(f"[âœ“] Daily Summary Saved for {preset_name} | Max(NOAA): {actual_max}")
            
        # é‡ç½®æœ€é«˜æ¸©ä»¥ä¾¿ç¬¬äºŒå¤©é‡æ–°å¼€å§‹
        state.max_temp_overall = -999.0

    def _get_dynamic_slug(self, template, offset):
        """æ ¹æ®ç«™ç‚¹æœ¬åœ°æ—¶é—´åŠ¨æ€ç”Ÿæˆ Slug"""
        import datetime as dt
        from datetime import timezone, timedelta
        
        utc_now = dt.datetime.now(timezone.utc)
        local_time = utc_now + timedelta(hours=offset)
        
        # Polymarket æ ¼å¼: month-day-year (lowercase, e.g. february-5-2026)
        month_name = local_time.strftime("%B").lower()
        day = local_time.day
        year = local_time.year
        
        return template.format(month=month_name, day=day, year=year)

        return template.format(month=month_name, day=day, year=year)

    def _record_trade_event(self, preset_name, city_name, local_time, signal, slug, contract, price, shares, reason):
        """è®°å½•å…·ä½“çš„äº¤æ˜“è§¦å‘ä¿¡å·åˆ°ç‹¬ç«‹æ–‡ä»¶ (data/trades/)"""
        data_dir = "data/trades"
        os.makedirs(data_dir, exist_ok=True)
        filename = f"{data_dir}/trade_history_{city_name}.csv"
        
        file_exists = os.path.isfile(filename)
        row = {
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'local_time': local_time,
            'signal_type': signal,
            'contract_slug': slug,
            'target_asset': contract,
            'execution_price': f"{price:.3f}" if price else "0.000",
            'shares': shares,
            'reasoning': reason,
            'is_dry_run': "TRUE" if self.config.DRY_RUN else "FALSE"
        }
        
        try:
            with open(filename, 'a', newline='', encoding='utf-8') as f:
                fieldnames = ['timestamp', 'local_time', 'signal_type', 'contract_slug', 'target_asset', 'execution_price', 'shares', 'reasoning', 'is_dry_run']
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                if not file_exists:
                    writer.writeheader()
                writer.writerow(row)
            logger.info(f"[{preset_name:8}] ğŸ“Š Trade event logged to {filename}")
        except Exception as e:
            logger.error(f"[{preset_name:8}] Failed to write trade log: {e}")

    def _record_data(self, filename, state, prices, signal, reason):
        """è®°å½•å®æ—¶æ•°æ®åˆ° CSV (å…¨é‡åŸå§‹è®°å½•ï¼Œå¹³é“ºæŠ¥ä»·åˆ—)"""
        if prices:
            logger.info(f"[DEBUG] Recording {len(prices)} price brackets to {filename}")
        else:
            logger.warning(f"[DEBUG] No prices fetched for {filename}")
            
        data_dir = os.path.dirname(filename)
        os.makedirs(data_dir, exist_ok=True)
        
        file_exists = os.path.isfile(filename)
        
        # åŸºç¡€å­—æ®µ (ä»…ä¿ç•™åŸå§‹è¾“å…¥)
        row = {
            'timestamp': state.timestamp,
            'local_time': state.local_time,
            'local_hour': f"{state.local_hour:.2f}",
            'noaa_curr': state.noaa_curr,
            'om_curr': state.om_curr,
            'om_fore': state.om_fore,
            'mn_curr': state.mn_curr,
            'mn_fore': state.mn_fore,
            'signal': signal,
            'reason': reason
        }
        
        # è®°å½• Yes, No çš„ Ask/Bid å’Œ Volume
        price_cols = []
        if prices:
            for title, p_data in prices.items():
                if isinstance(p_data, dict):
                    row[f"{title}_yes_ask"] = p_data.get('yes_ask')
                    row[f"{title}_yes_bid"] = p_data.get('yes_bid')
                    row[f"{title}_no_ask"] = p_data.get('no_ask')
                    row[f"{title}_no_bid"] = p_data.get('no_bid')
                    row[f"{title}_vol"] = p_data.get('vol')
                    price_cols.extend([
                        f"{title}_yes_ask", f"{title}_yes_bid", 
                        f"{title}_no_ask", f"{title}_no_bid", 
                        f"{title}_vol"
                    ])

        with open(filename, 'a', newline='') as f:
            base_fields = [
                'timestamp', 'local_time', 'local_hour', 
                'noaa_curr', 'om_curr', 'om_fore', 'mn_curr', 'mn_fore',
                'signal', 'reason'
            ]
            
            # å¦‚æœæ˜¯æ–°æ–‡ä»¶ï¼Œåªæœ‰åœ¨æ‹¿åˆ°æŠ¥ä»·åæ‰åˆ›å»ºå¹¶å†™å…¥ header
            if not file_exists:
                if not prices:
                    logger.warning(f"[{filename}] Skipping first log: No price data to initialize headers.")
                    return
                fieldnames = base_fields + sorted(price_cols)
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
            else:
                # è¯»å–ç¬¬ä¸€è¡Œè·å– header
                with open(filename, 'r') as fr:
                    reader = csv.reader(fr)
                    try:
                        existing_headers = next(reader)
                    except StopIteration:
                        # æ–‡ä»¶å­˜åœ¨ä½†ä¸ºç©ºçš„æƒ…å†µ
                        if not prices: return
                        existing_headers = base_fields + sorted(price_cols)
                        # è¿™é‡Œéœ€è¦é‡æ–°æ‰“å¼€æ–‡ä»¶å†™å…¥ headerï¼Œæˆ–è€…åœ¨æ­¤å¤„å¤„ç†
                        pass 
                
                # å…¼å®¹å¤„ç†ï¼šå¦‚æœç°æœ‰ header æ²¡æœ‰ä»·æ ¼åˆ—ï¼Œä½†åœ¨æ–°è¡Œä¸­æœ‰ï¼Œ
                # å¯¹äºå·²ç»åˆ›å»ºçš„æ–‡ä»¶ï¼Œæˆ‘ä»¬åªèƒ½å¿½ç•¥æˆ–è€…åœ¨æ­¤å¤„è¡¥å……ï¼ˆæ¯”è¾ƒå¤æ‚ï¼‰ã€‚
                # æ—¢ç„¶æˆ‘ä»¬ä¼šåˆ é™¤æ—§æ–‡ä»¶é‡å¯ï¼Œç¡®ä¿ç¬¬ä¸€æ¬¡æœ‰æ•°æ®å³å¯ã€‚
                writer = csv.DictWriter(f, fieldnames=existing_headers, extrasaction='ignore')
            
            writer.writerow(row)

    async def run_parallel(self, presets, interval=30):
        """å¹¶è¡Œè¿è¡Œå¤šä¸ª Preset"""
        logger.info(f"[*] Launching Multi-Location Engine: {presets}")
        logger.info(f"[*] Mode: {'DRY RUN' if self.config.DRY_RUN else 'REAL'}")
        
        # å¯åŠ¨åå°æŒä»“ç›‘æ§ä¸æŠ¥å‘Šä»»åŠ¡
        asyncio.create_task(self.monitor_and_report_loop(presets))
        
        tasks = [self.run_location_loop(p, interval) for p in presets]
        await asyncio.gather(*tasks)

    async def monitor_and_report_loop(self, presets, report_interval_hours=4):
        """æ¯éš” 4 å°æ—¶æ›´æ–°ä¸€æ¬¡çŠ¶æ€å¹¶å‘é€é’‰é’‰æ±‡æ€»æŠ¥å‘Š"""
        logger.info(f"[*] Postion Monitor Loop Started (Interval: {report_interval_hours}h)")
        
        while True:
            # é¦–å…ˆç­‰å¾…é—´éš”æ—¶é—´ï¼Œé¿å…å¯åŠ¨æ—¶ç«‹å³æ¨é€
            await asyncio.sleep(report_interval_hours * 3600)
            try:
                # 1. æ›´æ–°æ‰€æœ‰åœ°ç‚¹çš„æŒä»“çŠ¶æ€
                for p in presets:
                    self.pos_manager.update_positions_status(p)
                
                # 2. ç”Ÿæˆæ±‡æ€»æŠ¥å‘Šå¹¶å‘é€
                report_text = self.pos_manager.get_summary_report()
                
                webhook = os.getenv("DINGTALK_WEBHOOK")
                if webhook:
                    payload = {
                        "msgtype": "markdown",
                        "markdown": {
                            "title": "Polymarket æŒä»“æŠ¥å‘Š",
                            "text": report_text
                        }
                    }
                    requests.post(webhook, json=payload, timeout=10)
                    logger.info("[ç›‘æ§] å·²å‘é€æ¯ 4 å°æ—¶æŒä»“æ±‡æ€»æŠ¥å‘Š")
                else:
                    logger.warning("[ç›‘æ§] é’‰é’‰ Webhook æœªé…ç½®ï¼Œæ— æ³•å‘é€æ±‡æ€»æŠ¥å‘Š")

            except Exception as e:
                logger.error(f"[ç›‘æ§] æŠ¥å‘Šå¾ªç¯å¼‚å¸¸: {e}")


if __name__ == "__main__":
    import argparse
    from weather_price_monitor import PRESETS

    parser = argparse.ArgumentParser(description="Polymarket å¤©æ°”è‡ªåŠ¨äº¤æ˜“æœºå™¨äºº")
    parser.add_argument(
        "--presets", 
        nargs="+", 
        help="è¦è¿è¡Œçš„åœ°ç‚¹é¢„è®¾ (è‹¥ä¸æŒ‡å®šåˆ™è¯»å– .env ä¸­çš„ ACTIVE_LOCATIONS)"
    )
    parser.add_argument(
        "--interval", 
        type=int, 
        default=30, 
        help="é‡‡æ ·ä¸»å¾ªç¯é—´éš”(ç§’)ï¼Œé»˜è®¤ 30s"
    )
    
    args = parser.parse_args()
    
    # è·å–è¿è¡ŒåŸå¸‚ï¼šä¼˜å…ˆçº§ CLI > .env > Default
    active_cities = args.presets or QuantConfig.ACTIVE_LOCATIONS
    
    # è¿‡æ»¤æ‰ä¸å­˜åœ¨çš„åŸå¸‚
    valid_cities = [c for c in active_cities if c in PRESETS]
    if not valid_cities:
        logger.error(f"æ²¡æœ‰å¯è¿è¡Œçš„æœ‰æ•ˆåœ°ç‚¹! è¾“å…¥: {active_cities}")
        exit(1)
        
    logger.info(f"[*] å‡†å¤‡å¯åŠ¨åœ°ç‚¹: {valid_cities}")
    
    bot = WeatherBot()
    try:
        asyncio.run(bot.run_parallel(valid_cities, interval=args.interval))
    except KeyboardInterrupt:
        logger.info("[!] æ”¶åˆ°é€€å‡ºä¿¡å·ï¼Œæ­£åœ¨åœæ­¢æœåŠ¡...")
