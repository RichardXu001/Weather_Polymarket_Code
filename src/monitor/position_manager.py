import os
import csv
import json
import logging
from datetime import datetime
from typing import Dict, List, Optional
from datetime import timedelta
import requests

logger = logging.getLogger("PositionManager")

class PositionManager:
    """
    ç®¡ç†æŒä»“çš„å…¨ç”Ÿå‘½å‘¨æœŸ:
    PENDING (ä¸‹å•æœªæˆäº¤) -> FILLED (å·²æŒä»“) -> WIN/LOSS (å·²ç»“ç®—) -> REDEEMED (å·²èµå›)
    """
    
    def __init__(self, data_dir: str = "data/trades"):
        self.data_dir = data_dir
        os.makedirs(self.data_dir, exist_ok=True)
        self.gamma_api_url = "https://gamma-api.polymarket.com"

    def _get_trade_history_file(self, city_name: str) -> str:
        return f"{self.data_dir}/trade_history_{city_name.lower()}.csv"

    def record_pending_order(
        self,
        city_name: str,
        local_time: str,
        signal: str,
        slug: str,
        contract: str,
        price: float,
        shares: float,
        reason: str,
        order_id: str,
        is_dry_run: bool,
        *,
        yes_token_id: str = "",
        condition_id: str = "",
        outcome_index: str = "",
        neg_risk: str = "",
    ):
        """è®°å½•åˆå§‹ä¸‹å•çŠ¶æ€ (PENDING)"""
        filename = self._get_trade_history_file(city_name)
        file_exists = os.path.isfile(filename)

        row = {
            'timestamp': datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            'local_time': local_time,
            'signal_type': signal,
            'contract_slug': slug,
            'target_asset': contract,
            'execution_price': f"{price:.3f}",
            'shares': shares,
            'reasoning': reason,
            'order_id': order_id,
            'status': 'PENDING',
            'is_dry_run': "TRUE" if is_dry_run else "FALSE",
            'payout': 0.0,
            'redeemed': "FALSE",
            # New columns (best-effort): allow mapping to on-chain redemption.
            'yes_token_id': str(yes_token_id or ""),
            'condition_id': str(condition_id or ""),
            'outcome_index': str(outcome_index or ""),
            'neg_risk': str(neg_risk or ""),
        }

        fieldnames = [
            'timestamp', 'local_time', 'signal_type', 'contract_slug', 'target_asset',
            'execution_price', 'shares', 'reasoning', 'order_id', 'status', 'is_dry_run',
            'payout', 'redeemed',
            'yes_token_id', 'condition_id', 'outcome_index', 'neg_risk',
        ]

        # Header/schema migration: if file exists but headers differ, rewrite with superset schema.
        if file_exists:
            try:
                with open(filename, 'r', encoding='utf-8') as fr:
                    reader = csv.DictReader(fr)
                    existing_fields = reader.fieldnames or []
                    if set(fieldnames) != set(existing_fields):
                        rows_old = list(reader)
                        tmp = f"{filename}.tmp.{os.getpid()}"
                        with open(tmp, 'w', newline='', encoding='utf-8') as fw:
                            w = csv.DictWriter(fw, fieldnames=fieldnames)
                            w.writeheader()
                            for r in rows_old:
                                w.writerow({k: r.get(k, "") for k in fieldnames})
                        os.replace(tmp, filename)
            except Exception as e:
                logger.warning(f"Schema migration skipped for {filename}: {e}")

        # å…¼å®¹æ€§å¤„ç†ï¼šå¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä½† header ä¸åŒï¼Œåˆ™å¯èƒ½éœ€è¦å¤„ç†ï¼ˆæ­¤å¤„ç®€åŒ–ä¸ºå¼ºåˆ¶åŒ¹é…æˆ–åˆ é™¤æ—§æ–‡ä»¶ï¼‰
        if file_exists:
            with open(filename, 'r') as f:
                header = f.readline().strip().split(',')
                if 'status' not in header:
                    logger.warning(f"Old format detected in {filename}. Backing up and starting fresh.")
                    os.rename(filename, f"{filename}.bak")
                    file_exists = False

        with open(filename, 'a', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            if not file_exists:
                writer.writeheader()
            writer.writerow(row)
        logger.info(f"[{city_name}] ğŸ“ Order recorded: {order_id} (PENDING)")

    def update_positions_status(self, city_name: str, order_fetcher=None):
        """è½®è¯¢å¹¶æ›´æ–°è¯¥åŸå¸‚æ‰€æœ‰è®¢å•çš„çŠ¶æ€

        order_fetcher: optional callable(order_id: str, requested_size: float) -> OrderSummary-like
          Used to reconcile real orders (PENDING -> FILLED) without guessing.
        """
        filename = self._get_trade_history_file(city_name)
        if not os.path.exists(filename):
            return

        rows = []
        try:
            with open(filename, 'r', encoding='utf-8') as f:
                reader = csv.DictReader(f)
                rows = list(reader)
        except Exception as e:
            logger.error(f"Error reading trade history {filename}: {e}")
            return

        updated = False
        for row in rows:
            # é˜²å¾¡æ€§ç‚¹ 1: ç¡®ä¿ status å­—æ®µå­˜åœ¨
            if 'status' not in row:
                continue

            status = str(row.get('status', '')).upper()
            # å¦‚æœå·²æ ‡è®° redeemedï¼Œåˆ™å°†çŠ¶æ€æ¨è¿›åˆ° REDEEMEDï¼ˆç»ˆæ€ï¼‰ï¼Œä¿ç•™ payout ä»¥ä¾¿è®¡ç®—ç›ˆäºã€‚
            if status in {'WIN', 'LOSS'} and str(row.get('redeemed', 'FALSE')).upper() == 'TRUE':
                row['status'] = 'REDEEMED'
                updated = True
                continue

            if status == 'REDEEMED':
                continue

            # 1. å¤„ç† PENDING -> FILLED (å¦‚æœæ˜¯ Dry Run ç›´æ¥è½¬ FILLED)
            if status == 'PENDING':
                if str(row.get('is_dry_run', 'FALSE')).upper() == 'TRUE':
                    row['status'] = 'FILLED'
                    updated = True
                else:
                    # å®ç›˜ï¼šä¼˜å…ˆé€šè¿‡è®¢å•æ¥å£å¯¹è´¦ï¼Œé¿å…æ°¸è¿œå¡ä½ã€‚
                    if order_fetcher:
                        oid = str(row.get("order_id", "")).strip()
                        try:
                            req = float(row.get("shares", 0) or 0)
                        except ValueError:
                            req = 0.0
                        if oid and req > 0:
                            try:
                                summary = order_fetcher(oid, req)
                            except TypeError:
                                # Backward compat: order_fetcher(order_id) -> summary
                                summary = order_fetcher(oid)
                            if summary:
                                filled = getattr(summary, "filled_size", None)
                                status_o = getattr(summary, "status", None)
                                try:
                                    filled_f = float(filled or 0.0)
                                except (TypeError, ValueError):
                                    filled_f = 0.0
                                if filled_f > 0:
                                    row["status"] = "FILLED"
                                    # ä¿®æ­£ shares ä¸ºå®é™…æˆäº¤ä»½é¢ï¼Œé¿å…åç»­ PnL/èµå›è®¡ç®—åå·®ã€‚
                                    row["shares"] = f"{filled_f:.6f}"
                                    updated = True
                                elif status_o and str(status_o).upper() in {"CANCELED", "CANCELLED", "REJECTED", "FAILED", "EXPIRED"}:
                                    row["status"] = "FAILED"
                                    updated = True

                    # å®ç›˜: å…ˆå°è¯•ç›´æ¥åˆ¤å®šæ˜¯å¦å·²ç»“ç®—ï¼ˆå…è®¸ PENDING -> WIN/LOSS è·³è½¬ï¼Œ
                    # ä»¥é¿å…å› ä¸ºç¼ºå°‘è®¢å•å›æŠ¥æ¥å£å¯¼è‡´æ°¸è¿œå¡åœ¨ PENDINGï¼‰ã€‚
                    slug = row.get('contract_slug')
                    asset = row.get('target_asset')
                    if slug and asset:
                        outcome = self._check_market_resolution(slug, asset)
                        if outcome:
                            row['status'] = outcome  # WIN or LOSS
                            row['payout'] = 1.0 if outcome == 'WIN' else 0.0
                            updated = True
                            continue

                    # å¯é€‰ï¼šå…è®¸é€šè¿‡ç¯å¢ƒå˜é‡åšâ€œå‡å®šæˆäº¤â€ï¼Œä»¥è§£é”åç»­ WIN/LOSS è½®è¯¢ã€‚
                    assume_after = os.getenv("ASSUME_FILLED_AFTER_MINUTES", "").strip()
                    if assume_after:
                        try:
                            mins = float(assume_after)
                        except ValueError:
                            mins = None
                        if mins is not None:
                            ts = row.get('timestamp', '')
                            try:
                                created = datetime.strptime(str(ts).strip(), "%Y-%m-%d %H:%M:%S")
                            except Exception:
                                created = None
                            if created and datetime.now() - created >= timedelta(minutes=mins):
                                row['status'] = 'FILLED'
                                updated = True

            # 2. å¤„ç† FILLED -> WIN/LOSS
            status = str(row.get('status', '')).upper()
            if status == 'FILLED':
                # é˜²å¾¡æ€§ç‚¹ 2: ç¡®ä¿ slug å’Œ target_asset å­˜åœ¨
                slug = row.get('contract_slug')
                asset = row.get('target_asset')
                if slug and asset:
                    outcome = self._check_market_resolution(slug, asset)
                    if outcome:
                        row['status'] = outcome # WIN or LOSS
                        row['payout'] = 1.0 if outcome == 'WIN' else 0.0
                        updated = True

        if updated:
            with open(filename, 'w', newline='', encoding='utf-8') as f:
                fieldnames = [
                    'timestamp', 'local_time', 'signal_type', 'contract_slug', 'target_asset',
                    'execution_price', 'shares', 'reasoning', 'order_id', 'status', 'is_dry_run',
                    'payout', 'redeemed',
                    'yes_token_id', 'condition_id', 'outcome_index', 'neg_risk',
                ]
                writer = csv.DictWriter(f, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(rows)
            logger.info(f"[{city_name}] ğŸ”„ Trade history updated.")

    def _check_market_resolution(self, slug: str, target_contract: str) -> Optional[str]:
        """æ£€æŸ¥å¸‚åœºæ˜¯å¦å·²ç»“ç®—ï¼Œå¹¶è¿”å›ç»“æœ (WIN/LOSS)"""
        try:
            url = f"{self.gamma_api_url}/events?slug={slug}"
            resp = requests.get(url, timeout=10)
            if resp.status_code == 200:
                data = resp.json()
                if not data: return None
                
                event = data[0]
                # Gamma æ¥å£åœ¨éƒ¨åˆ†å·²ç»“ç®—äº‹ä»¶ä¸Š resolved å¯èƒ½ä¸º Noneï¼Œä½† closed=True ä¸” outcomePrices å·²äºŒå€¼åŒ–ã€‚
                if not (event.get('resolved') or event.get('closed')):
                    return None
                
                # æ‰¾åˆ°è·èƒœçš„åˆçº¦
                markets = event.get('markets', [])
                for m in markets:
                    title = m.get('groupItemTitle', m.get('question'))
                    if title and self._contract_title_match(title, target_contract):
                        p_data = self._normalize_outcome_prices(m.get('outcomePrices', []))
                        if not p_data or len(p_data) < 2:
                            return None
                        outcomes = m.get('outcomes', [])
                        if not isinstance(outcomes, list):
                            outcomes = []
                        # å…¼å®¹ï¼šGamma çš„ outcomes/outcomePrices é¡ºåºä¸ä¿è¯ä¸º [Yes, No]ã€‚
                        idx_yes = None
                        idx_no = None
                        for i, o in enumerate(outcomes):
                            o_norm = str(o).strip().lower()
                            if o_norm == 'yes':
                                idx_yes = i
                            elif o_norm == 'no':
                                idx_no = i
                        if idx_yes is not None and idx_no is not None and idx_yes < len(p_data) and idx_no < len(p_data):
                            yes_price = self._safe_float(p_data[idx_yes])
                            no_price = self._safe_float(p_data[idx_no])
                        else:
                            # å›é€€åˆ°æ—§é€»è¾‘ï¼ˆä»…åœ¨ outcomes ä¸å¯ç”¨æ—¶ä½¿ç”¨ï¼‰
                            yes_price = self._safe_float(p_data[0])
                            no_price = self._safe_float(p_data[1])
                        if yes_price is None or no_price is None:
                            return None
                        # ä»…åœ¨äºŒå€¼åŒ–ç»“ç®—åæ‰åˆ¤èƒœè´Ÿï¼Œé¿å…æŠŠæœªç»“ç®—æ¦‚ç‡å½“ç»“æœã€‚
                        if not self._is_binary_outcome(yes_price, no_price):
                            return None
                        return 'WIN' if yes_price > no_price else 'LOSS'
        except Exception as e:
            logger.error(f"Error checking resolution for {slug}: {e}")
        return None

    @staticmethod
    def _safe_float(v) -> Optional[float]:
        try:
            return float(v)
        except (TypeError, ValueError):
            return None

    @staticmethod
    def _normalize_outcome_prices(p_data):
        if isinstance(p_data, list):
            return p_data
        if isinstance(p_data, str):
            try:
                parsed = json.loads(p_data)
                if isinstance(parsed, list):
                    return parsed
            except json.JSONDecodeError:
                return []
        return []

    @staticmethod
    def _is_binary_outcome(yes_price: float, no_price: float) -> bool:
        # ç»“ç®—åé€šå¸¸ä¼šéå¸¸æ¥è¿‘ 1/0ï¼›è¿™é‡Œç»™å°‘é‡å®¹å·®å…¼å®¹ä¸åŒç²¾åº¦ã€‚
        return (yes_price >= 0.999 and no_price <= 0.001) or (no_price >= 0.999 and yes_price <= 0.001) or \
               (yes_price >= 0.999 and no_price <= 0.01) or (no_price >= 0.999 and yes_price <= 0.01)

    @staticmethod
    def _contract_title_match(title: str, target_contract: str) -> bool:
        title_norm = str(title).strip().lower()
        target_norm = str(target_contract).strip().lower()
        return title_norm == target_norm or target_norm in title_norm

    def get_summary_report(self) -> str:
        """ç”Ÿæˆå…¨å±€æŒä»“æ±‡æ€»æŠ¥å‘Šå­—æ®µ (è‡ªåŠ¨åˆå¹¶ç›¸åŒåˆçº¦çš„æŒä»“)"""
        if not os.path.exists(self.data_dir):
            return "ğŸ“­ å½“å‰æ— æ´»è·ƒæŒä»“æˆ–è¿‘æœŸäº¤æ˜“è®°å½•ã€‚"
            
        all_files = [f for f in os.listdir(self.data_dir) if f.startswith("trade_history_")]
        if not all_files:
            return "ğŸ“­ å½“å‰æ— æ´»è·ƒæŒä»“æˆ–è¿‘æœŸäº¤æ˜“è®°å½•ã€‚"
            
        report = "ğŸ“Š Polymarket æŒä»“æ±‡æ€»æŠ¥å‘Š\n"
        report += f"â° ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n"
        
        # èšåˆå­—å…¸: key=(city, asset, status), value={'shares': float, 'total_cost': float}
        active_agg = {}
        settled_count = 0
        total_profit = 0.0
        
        for f in all_files:
            city = f.replace("trade_history_", "").replace(".csv", "").upper()
            try:
                with open(os.path.join(self.data_dir, f), 'r', encoding='utf-8') as file:
                    reader = csv.DictReader(file)
                    for row in reader:
                        # æç«¯é˜²å¾¡ï¼šè·³è¿‡ç¼ºå°‘æ ¸å¿ƒå­—æ®µçš„è¡Œ
                        if not row.get('status') or not row.get('shares'):
                            continue
                        # æ±‡æ€»æŠ¥å‘Šä»…ç»Ÿè®¡çœŸå®å•ï¼Œå¿½ç•¥ dry run è®°å½•
                        if str(row.get('is_dry_run', 'FALSE')).upper() == 'TRUE':
                            continue
                            
                        status = row['status']
                        asset = row.get('target_asset', 'Unknown')
                        shares = float(row.get('shares', 0))
                        price = float(row.get('execution_price', 0))
                        
                        if status in ['PENDING', 'FILLED']:
                            key = (city, asset, status)
                            if key not in active_agg:
                                active_agg[key] = {'shares': 0.0, 'total_cost': 0.0}
                            active_agg[key]['shares'] += shares
                            active_agg[key]['total_cost'] += price * shares
                            
                        elif status in ['WIN', 'LOSS', 'REDEEMED']:
                            settled_count += 1
                            payout = float(row.get('payout', 0))
                            profit = (payout - price) * shares
                            total_profit += profit
                            redeem_tag = "âœ… å·²èµå›" if row.get('redeemed') == 'TRUE' else "âš ï¸ å¾…èµå›"
                            report += f"ğŸ {city} æœ€ç»ˆç»“æœ:\n"
                            # REDEEMED æ—¶ç”¨ payout åæ¨ WIN/LOSSï¼ˆpayout=1.0 è§†ä¸º WINï¼Œå¦åˆ™è§†ä¸º LOSSï¼‰
                            if status == 'REDEEMED':
                                inferred = 'WIN' if payout >= 0.999 else 'LOSS'
                                report += f"- åˆçº¦: {asset} | ç»“æœ: {inferred} (REDEEMED)\n"
                            else:
                                report += f"- åˆçº¦: {asset} | ç»“æœ: {status}\n"
                            report += f"- PnL: ${profit:+.2f} | {redeem_tag}\n\n"
            except Exception as e:
                logger.error(f"Error processing {f} for report: {e}")

        # ç”Ÿæˆæ´»è·ƒæŒä»“æŠ¥å‘Š (ä»èšåˆæ•°æ®ä¸­)
        if active_agg:
            for (city, asset, status), data in active_agg.items():
                total_shares = data['shares']
                avg_price = data['total_cost'] / total_shares if total_shares > 0 else 0.0
                
                report += f"ğŸ“ {city}: {asset}\n"
                report += f"- çŠ¶æ€: {status} | ä»½é¢: {total_shares:.1f}\n"
                report += f"- å‡ä»·: ${avg_price:.3f} | ROI: æŒæœ‰ä¸­\n\n"

        if not active_agg and settled_count == 0:
            return "ğŸ“­ å½“å‰æ— æ´»è·ƒæŒä»“æˆ–è¿‘æœŸäº¤æ˜“è®°å½•ã€‚"
            
        report += f"---\nğŸ’° ç´¯è®¡ç›ˆäº (å·²ç»“ç®—): ${total_profit:+.2f}"
        return report

    def mark_redeemed_by_condition(self, condition_id: str, outcome_index: int) -> int:
        """Best-effort: mark matching WIN/LOSS rows as redeemed and advance to REDEEMED."""
        if not condition_id:
            return 0
        updated_rows = 0
        all_files = [f for f in os.listdir(self.data_dir) if f.startswith("trade_history_")]
        for f in all_files:
            path = os.path.join(self.data_dir, f)
            try:
                with open(path, "r", encoding="utf-8") as fr:
                    reader = csv.DictReader(fr)
                    rows = list(reader)
                    fieldnames = reader.fieldnames or []
            except Exception:
                continue

            changed = False
            for row in rows:
                if str(row.get("is_dry_run", "FALSE")).upper() == "TRUE":
                    continue
                if str(row.get("status", "")).upper() not in {"WIN", "LOSS"}:
                    continue
                if str(row.get("redeemed", "FALSE")).upper() == "TRUE":
                    continue
                if str(row.get("condition_id", "")).strip() != str(condition_id).strip():
                    continue
                try:
                    idx = int(str(row.get("outcome_index", "")).strip() or "0")
                except ValueError:
                    continue
                if idx != int(outcome_index):
                    continue
                row["redeemed"] = "TRUE"
                row["status"] = "REDEEMED"
                changed = True
                updated_rows += 1

            if changed:
                # Ensure schema includes our superset.
                base = [
                    'timestamp', 'local_time', 'signal_type', 'contract_slug', 'target_asset',
                    'execution_price', 'shares', 'reasoning', 'order_id', 'status', 'is_dry_run',
                    'payout', 'redeemed',
                    'yes_token_id', 'condition_id', 'outcome_index', 'neg_risk',
                ]
                fn = base if set(base).issuperset(set(fieldnames or [])) else (fieldnames or base)
                with open(path, "w", newline="", encoding="utf-8") as fw:
                    w = csv.DictWriter(fw, fieldnames=fn)
                    w.writeheader()
                    for r in rows:
                        w.writerow({k: r.get(k, "") for k in fn})
        return updated_rows
